nohup: ignoring input
[2025-11-27 04:34:42,649] [WARNING] [runner.py:232:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.
[2025-11-27 04:34:42,649] [INFO] [runner.py:630:main] cmd = /home/phayi/anaconda3/envs/more/bin/python3.1 -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbMF19 --master_addr=127.0.0.1 --master_port=17621 --enable_each_rank_log=None --log_level=info ./finetune.py --model_name_or_path /root/data/t5-base --tasks cola mnli mrpc qnli qqp rte sst2 stsb --max_length 128 --use_lora True --lora_rank 8 --lora_alpha 32 --target_modules q k v o wi wo --expert_kernel_sizes 2 2 4 4 8 8 16 16 --moe_top_k 2 --output_dir ./save/MoRE_2244881616_no_sum --eval_strategy steps --eval_steps 1000 --save_steps 1000 --save_total_limit 5 --num_train_epochs 1 --per_device_train_batch_size 128 --per_device_eval_batch_size 512 --gradient_accumulation_steps 1 --learning_rate 3e-4 --weight_decay 0.01 --warmup_steps 500 --logging_dir ./save/MoRE_2244881616_no_sum/logs --logging_steps 100 --load_best_model_at_end True --dataloader_num_workers 16 --bf16 True --seed 2023
[2025-11-27 04:34:46,404] [INFO] [launch.py:155:main] 0 NCCL_P2P_DISABLE=0
[2025-11-27 04:34:46,404] [INFO] [launch.py:155:main] 0 NCCL_IB_DISABLE=0
[2025-11-27 04:34:46,404] [INFO] [launch.py:162:main] WORLD INFO DICT: {'localhost': [0]}
[2025-11-27 04:34:46,404] [INFO] [launch.py:168:main] nnodes=1, num_local_procs=1, node_rank=0
[2025-11-27 04:34:46,404] [INFO] [launch.py:179:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0]})
[2025-11-27 04:34:46,404] [INFO] [launch.py:180:main] dist_world_size=1
[2025-11-27 04:34:46,404] [INFO] [launch.py:184:main] Setting CUDA_VISIBLE_DEVICES=0
[2025-11-27 04:34:46,405] [INFO] [launch.py:272:main] process 1788800 spawned with command: ['/home/phayi/anaconda3/envs/more/bin/python3.1', '-u', './finetune.py', '--local_rank=0', '--model_name_or_path', '/root/data/t5-base', '--tasks', 'cola', 'mnli', 'mrpc', 'qnli', 'qqp', 'rte', 'sst2', 'stsb', '--max_length', '128', '--use_lora', 'True', '--lora_rank', '8', '--lora_alpha', '32', '--target_modules', 'q', 'k', 'v', 'o', 'wi', 'wo', '--expert_kernel_sizes', '2', '2', '4', '4', '8', '8', '16', '16', '--moe_top_k', '2', '--output_dir', './save/MoRE_2244881616_no_sum', '--eval_strategy', 'steps', '--eval_steps', '1000', '--save_steps', '1000', '--save_total_limit', '5', '--num_train_epochs', '1', '--per_device_train_batch_size', '128', '--per_device_eval_batch_size', '512', '--gradient_accumulation_steps', '1', '--learning_rate', '3e-4', '--weight_decay', '0.01', '--warmup_steps', '500', '--logging_dir', './save/MoRE_2244881616_no_sum/logs', '--logging_steps', '100', '--load_best_model_at_end', 'True', '--dataloader_num_workers', '16', '--bf16', 'True', '--seed', '2023']
/home/phayi/anaconda3/envs/more/bin/python3.1: can't open file '/root/MoRE/script/./finetune.py': [Errno 2] No such file or directory
[2025-11-27 04:34:47,406] [INFO] [launch.py:335:sigkill_handler] Killing subprocess 1788800
[2025-11-27 04:34:47,407] [ERROR] [launch.py:341:sigkill_handler] ['/home/phayi/anaconda3/envs/more/bin/python3.1', '-u', './finetune.py', '--local_rank=0', '--model_name_or_path', '/root/data/t5-base', '--tasks', 'cola', 'mnli', 'mrpc', 'qnli', 'qqp', 'rte', 'sst2', 'stsb', '--max_length', '128', '--use_lora', 'True', '--lora_rank', '8', '--lora_alpha', '32', '--target_modules', 'q', 'k', 'v', 'o', 'wi', 'wo', '--expert_kernel_sizes', '2', '2', '4', '4', '8', '8', '16', '16', '--moe_top_k', '2', '--output_dir', './save/MoRE_2244881616_no_sum', '--eval_strategy', 'steps', '--eval_steps', '1000', '--save_steps', '1000', '--save_total_limit', '5', '--num_train_epochs', '1', '--per_device_train_batch_size', '128', '--per_device_eval_batch_size', '512', '--gradient_accumulation_steps', '1', '--learning_rate', '3e-4', '--weight_decay', '0.01', '--warmup_steps', '500', '--logging_dir', './save/MoRE_2244881616_no_sum/logs', '--logging_steps', '100', '--load_best_model_at_end', 'True', '--dataloader_num_workers', '16', '--bf16', 'True', '--seed', '2023'] exits with return code = 2
